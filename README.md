# voice-era - Sign Language Video Calling Platform

A real-time video calling platform with integrated sign language recognition, designed to help deaf/mute individuals communicate effectively.

## ğŸŒŸ Features

### Core Video Calling
- **Multi-participant video calls** (up to 6 participants)
- **WebRTC peer-to-peer connections** for high-quality video/audio
- **Room-based system** with unique room IDs (like Google Meet/Zoom)
- **Camera and microphone controls** (mute/unmute, video on/off)
- **Graceful fallback** for users without camera/microphone access

### Sign Language Recognition
- **Real-time ISL recognition** using custom TensorFlow model
- **106 sign classes** including:
  - ISL Alphabet (A-Z)
  - Numbers (1, 3-9)
  - Common words (namastey, help, accept, home, school, etc.)
- **MediaPipe integration** for hand/face landmark detection
- **Live captions** with confidence scores
- **Dual-input model** (128x128 image + 63 landmark features)

### Communication Features
- **Real-time chat** during video calls
- **Live caption display** with participant names
- **Shared caption area** for all participants
- **Caption overlay** on video feeds
- **Message history** and caption history

### User Experience
- **Beautiful modern UI** with gradient design and glassmorphism effects
- **Responsive layout** for desktop and mobile
- **Professional controls** similar to Google Meet/Zoom
- **Real-time updates** via WebSocket connections
- **Error handling** and graceful degradation

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- Node.js 16+
- MongoDB
- Modern web browser with WebRTC support

### Installation

1. **Backend Setup**
```bash
cd backend
pip install -r requirements.txt
```

2. **Frontend Setup**
```bash
cd frontend
yarn install
```

3. **Environment Configuration**
```bash
# backend/.env
MONGO_URL="mongodb://localhost:27017"
DB_NAME="voice-era_db"
CORS_ORIGINS="*"

# frontend/.env
REACT_APP_BACKEND_URL=http://localhost:8001
```

### Running the Application

1. **Start MongoDB**
```bash
mongod
```

2. **Start Backend**
```bash
cd backend
python server.py
```

3. **Start Frontend**
```bash
cd frontend
yarn start
```

4. **Access the Application**
- Open http://localhost:3000 in your browser
- Create a room or join with a room ID
- Allow camera/microphone access for full functionality

## ğŸŒ Deployment with ngrok

For testing with friends or remote deployment:

1. **Install ngrok**
```bash
npm install -g ngrok
```

2. **Expose Backend**
```bash
ngrok http 8001
```

3. **Update Frontend Environment**
```bash
# Update frontend/.env with ngrok URL
REACT_APP_BACKEND_URL=https://abc123.ngrok.io
```

4. **Expose Frontend**
```bash
ngrok http 3000
# Share this URL with friends
```

## ğŸ“ Project Structure

```
voice-era/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ server.py              # Main FastAPI application
â”‚   â”œâ”€â”€ sign_model.h5          # Trained TensorFlow model
â”‚   â”œâ”€â”€ labels.joblib          # Sign language class labels
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â””â”€â”€ .env                   # Backend environment variables
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ HomePage.js     # Room creation/joining
â”‚   â”‚   â”‚   â”œâ”€â”€ RoomPage.js     # Main video call interface
â”‚   â”‚   â”‚   â”œâ”€â”€ VideoCall.js    # Video grid component
â”‚   â”‚   â”‚   â”œâ”€â”€ Chat.js         # Chat functionality
â”‚   â”‚   â”‚   â””â”€â”€ Captions.js     # Caption display
â”‚   â”‚   â”œâ”€â”€ App.js             # Main React component
â”‚   â”‚   â””â”€â”€ App.css            # Styling and animations
â”‚   â”œâ”€â”€ package.json           # Node.js dependencies
â”‚   â””â”€â”€ .env                   # Frontend environment variables
â””â”€â”€ README.md                  # This file
```

## ğŸ¤– Machine Learning Model

### Model Architecture
- **Input Layer 1**: 128x128x3 RGB image
- **Input Layer 2**: 63 MediaPipe landmarks (21 hand landmarks Ã— 3 coordinates)
- **CNN Layers**: 3 convolutional layers for image processing
- **Dense Layers**: Fully connected layers for landmark processing
- **Concatenation**: Combined image and landmark features
- **Output**: 106 classes with softmax activation

### Supported Signs
The model recognizes 106 different signs including:
- **Alphabet**: A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z
- **Numbers**: 1, 3, 4, 5, 6, 7, 8, 9
- **Common Words**: accept, age, bag, book, help, home, idea, namastey, school, technology, etc.

## ğŸ¯ API Endpoints

### Room Management
- `POST /api/rooms` - Create a new room
- `GET /api/rooms/{room_id}` - Get room details
- `POST /api/rooms/{room_id}/join` - Join a room

### Sign Language Recognition
- `POST /api/predict` - Predict sign from image data
- `GET /api/rooms/{room_id}/captions` - Get room captions

### WebSocket Events
- `join_room` - Join a Socket.IO room
- `webrtc_offer/answer/ice_candidate` - WebRTC signaling
- `send_message` - Send chat messages
- `new_caption` - Broadcast new captions

## ğŸ› ï¸ Troubleshooting

### Common Issues

1. **Camera/Microphone Access Denied**
   - Grant camera/microphone permissions in browser
   - The app works in chat-only mode without media access

2. **WebRTC Connection Failed**
   - Ensure both users are on the same network or using ngrok
   - Check firewall settings for WebRTC ports

3. **Sign Language Recognition Not Working**
   - Verify camera is working and has good lighting
   - Check that TensorFlow model loaded successfully in backend logs

---

**voice-era** - Bridging communication gaps through technology ğŸ¤Ÿ
